{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/junio/Desktop/Ju/mywaytohealth2020/jupyter/data/01.PATIENTS_VISITES-no_control_no_spurious_data-median-imputation_ADASYN.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing and evaluation of the regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    576\n",
       "2    569\n",
       "0    569\n",
       "3    566\n",
       "Name: iah_class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sklearn.utils.shuffle(df)\n",
    "selected_fields = ['age', 'egfdrs001', 'nycturie_nb', 'score_depression', 'imc', 'perimetre_cervical', 'tour_de_hanches', 'padiast']\n",
    "x = df[selected_fields]\n",
    "y = df[['iah_class']]\n",
    "#y = y.astype({\"iah_class\": int})\n",
    "#x.isnull().sum()/len(df)*100\n",
    "y.iah_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y.values.ravel(),test_size=0.33,stratify=y.values.ravel())\n",
    "n_iterations = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=ExtraTreesClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = ExtraTreesClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1527, 8)\n",
      "(1527,)\n",
      "(753, 8)\n",
      "[2 3 0 3 2 0 3 1 3 3 2 3 2 0 0 0 2 1 1 3 3 3 3 2 0 1 3 0 3 2 2 2 2 0 3 1 0\n",
      " 2 2 1 0 2 2 0 2 2 0 1 2 2 3 3 3 3 1 2 0 1 2 2 3 1 3 1 2 3 2 2 2 3 3 0 0 0\n",
      " 3 2 2 0 2 3 2 1 0 2 1 3 1 0 2 3 2 0 2 2 0 3 1 3 1 0 3 3 1 3 3 1 0 2 3 3 2\n",
      " 1 0 1 1 3 0 3 1 1 3 2 1 3 2 0 1 3 0 2 0 0 1 3 0 0 1 1 2 3 2 1 2 0 0 0 0 0\n",
      " 3 2 2 1 1 1 2 0 0 0 2 1 2 1 3 3 0 0 1 0 2 0 2 0 1 3 1 0 2 0 3 1 1 3 1 0 3\n",
      " 2 0 3 3 2 0 2 2 1 3 0 1 3 2 2 0 0 0 0 2 0 1 3 2 3 0 2 3 3 2 3 2 2 2 0 0 1\n",
      " 1 3 1 0 1 0 1 0 1 2 3 1 3 2 1 1 0 0 1 2 1 1 1 1 2 2 0 1 3 0 1 3 1 3 3 1 3\n",
      " 1 1 2 1 3 0 1 2 0 1 2 2 2 0 1 0 1 0 3 0 1 3 0 0 1 0 0 3 1 1 2 3 0 1 1 0 3\n",
      " 0 1 1 3 3 0 3 1 1 2 1 3 3 2 2 1 3 1 2 2 2 0 3 1 1 2 3 3 3 1 2 1 0 1 2 2 1\n",
      " 2 0 1 2 3 0 1 0 1 1 2 1 1 1 3 2 1 2 1 1 0 3 3 1 2 1 1 0 0 2 0 0 0 1 1 1 0\n",
      " 0 0 2 3 2 3 2 1 0 1 3 3 1 0 2 3 1 3 2 3 2 1 0 3 3 0 3 3 0 0 0 1 1 1 1 2 2\n",
      " 3 3 3 3 2 3 1 2 3 2 0 2 3 2 2 0 2 2 1 0 1 2 0 2 2 1 2 0 1 1 3 3 3 2 0 2 2\n",
      " 0 1 2 1 3 2 0 0 0 3 3 0 2 3 2 3 2 3 3 3 2 1 2 2 0 0 2 3 0 0 3 3 1 2 0 1 1\n",
      " 1 1 0 3 2 3 0 0 1 0 2 0 0 0 2 2 2 2 1 0 1 2 0 3 3 1 0 2 0 3 1 3 3 2 0 2 3\n",
      " 3 2 2 2 0 1 0 2 1 1 2 3 0 2 1 0 1 0 3 2 3 3 1 3 3 0 3 3 0 0 0 0 0 0 1 0 2\n",
      " 3 3 0 0 0 0 1 2 3 2 1 2 0 0 2 1 0 1 2 2 0 3 0 1 1 1 0 0 0 1 1 0 1 3 0 2 2\n",
      " 2 2 3 2 3 3 0 0 1 3 3 0 2 2 0 3 1 1 3 3 3 0 0 3 0 3 3 0 1 3 2 0 1 2 3 2 3\n",
      " 3 3 2 0 0 3 1 2 1 0 3 0 2 1 3 2 2 3 0 3 0 2 0 1 2 2 1 1 1 3 0 0 1 2 0 1 1\n",
      " 1 2 1 3 0 2 1 1 1 0 1 1 3 3 0 1 2 1 1 1 2 2 3 3 3 3 2 3 0 3 1 1 1 0 2 1 2\n",
      " 3 1 2 3 2 1 0 1 0 2 0 1 3 0 1 3 2 1 0 3 1 2 3 3 1 3 3 2 3 0 2 1 3 1 2 3 0\n",
      " 3 0 3 3 2 2 2 1 2 1 3 2 0]\n",
      "(753,)\n"
     ]
    }
   ],
   "source": [
    "y_pred=xgb.predict(x_test)\n",
    "y_proba=xgb.predict_proba(x_test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.ravel())\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100 rounds random sampling validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The problem is imbalanced, the averageing MUST be 'macro' to reflect the minority class missclassifications\n",
    "if True:\n",
    "    selected_fields = ['age', 'egfdrs001', 'nycturie_nb', 'score_depression', 'imc', 'perimetre_cervical', 'tour_de_hanches', 'padiast']\n",
    "    n_folds = 100\n",
    "    df = pd.read_csv('/home/junio/Desktop/Ju/mywaytohealth2020/jupyter/data/01.PATIENTS_VISITES-no_control_no_spurious_data-median-imputation.csv',sep=',')\n",
    "    comb_to_scores_MAP = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    print(selected_fields)\n",
    "    for fold in range(n_folds):\n",
    "        df = sklearn.utils.shuffle(df)\n",
    "        x = df[selected_fields]\n",
    "        y = df[['iah_class']]\n",
    "        y = y.astype({\"iah_class\": int})\n",
    "        x, y = ADASYN().fit_resample(x, y)\n",
    "        x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y.values.ravel(),test_size=0.33,stratify=y.values.ravel())        \n",
    "        #dfTemp = pd.DataFrame({'iah_class':y_train})\n",
    "        #print(dfTemp.iah_class.value_counts())\n",
    "        #print(dfTemp.shape)\n",
    "\n",
    "        gnb = ExtraTreesClassifier(n_estimators=150)\n",
    "        gnb.fit(x_train, y_train)\n",
    "        y_pred = gnb.predict(x_test)\n",
    "        y_prob = gnb.predict_proba(x_test)\n",
    "\n",
    "        comb_to_scores_MAP[0] += f1_score(y_test, y_pred, average='micro')\n",
    "        comb_to_scores_MAP[1] += f1_score(y_test, y_pred, average='macro')\n",
    "        comb_to_scores_MAP[2] += f1_score(y_test, y_pred, average='weighted')\n",
    "        comb_to_scores_MAP[3] += roc_auc_score(y_test, y_prob, average='macro', multi_class = 'ovr')\n",
    "        comb_to_scores_MAP[4] += roc_auc_score(y_test, y_prob, average='macro', multi_class = 'ovo')        \n",
    "        comb_to_scores_MAP[5] += roc_auc_score(y_test, y_prob, average='weighted', multi_class = 'ovr')\n",
    "        comb_to_scores_MAP[6] += roc_auc_score(y_test, y_prob, average='weighted', multi_class = 'ovo')                \n",
    "        comb_to_scores_MAP[7] += accuracy_score(y_test, y_pred)\n",
    "        comb_to_scores_MAP[8] += precision_score(y_test, y_pred, average='micro',zero_division=0)\n",
    "        comb_to_scores_MAP[9] += recall_score(y_test, y_pred, average='micro')\n",
    "        comb_to_scores_MAP[10] += precision_score(y_test, y_pred, average='macro')\n",
    "        comb_to_scores_MAP[11] += recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    comb_to_scores_MAP[0] = comb_to_scores_MAP[0] / n_folds\n",
    "    comb_to_scores_MAP[1] = comb_to_scores_MAP[1] / n_folds\n",
    "    comb_to_scores_MAP[2] = comb_to_scores_MAP[2] / n_folds\n",
    "    comb_to_scores_MAP[3] = comb_to_scores_MAP[3] / n_folds\n",
    "    comb_to_scores_MAP[4] = comb_to_scores_MAP[4] / n_folds\n",
    "    comb_to_scores_MAP[5] = comb_to_scores_MAP[5] / n_folds\n",
    "    comb_to_scores_MAP[6] = comb_to_scores_MAP[6] / n_folds\n",
    "    comb_to_scores_MAP[7] = comb_to_scores_MAP[7] / n_folds\n",
    "    comb_to_scores_MAP[8] = comb_to_scores_MAP[8] / n_folds\n",
    "    comb_to_scores_MAP[9] = comb_to_scores_MAP[9] / n_folds\n",
    "    comb_to_scores_MAP[10] = comb_to_scores_MAP[10] / n_folds\n",
    "    comb_to_scores_MAP[11] = comb_to_scores_MAP[11] / n_folds\n",
    "    print('F1-Micro',comb_to_scores_MAP[0])\n",
    "    print('F1-Macro',comb_to_scores_MAP[1])\n",
    "    print('F1-Weighted',comb_to_scores_MAP[2])\n",
    "    print('AUC-ROC-Macro-ovr',comb_to_scores_MAP[3])\n",
    "    print('AUC-ROC-Macro-ovo',comb_to_scores_MAP[4])\n",
    "    print('AUC-ROC-Weighted-ovr',comb_to_scores_MAP[5],\"=> use ovr instead of ovo\")\n",
    "    print('AUC-ROC-Weighted-ovo',comb_to_scores_MAP[6])\n",
    "    print('Accuracy',comb_to_scores_MAP[7])\n",
    "    print('Precision-micro',comb_to_scores_MAP[8])\n",
    "    print('Recall-micro',comb_to_scores_MAP[9])\n",
    "    print('Precision-macro',comb_to_scores_MAP[10])\n",
    "    print('Recall-macro',comb_to_scores_MAP[11])\n",
    "\n",
    "\n",
    "    target_names = ['normal', 'mild', 'moderate', 'severe']\n",
    "    print(classification_report(y_test, y_pred, labels=[0, 1, 2, 3], target_names=target_names))\n",
    "\n",
    "    #https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix : \\n', cm)\n",
    "\n",
    "    total=sum(sum(cm))\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy=(cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3])/total\n",
    "    print ('Accuracy : ', accuracy)\n",
    "\n",
    "    sensitivity=[0,0,0,0]\n",
    "    sensitivity[0] = cm[0,0]/(cm[0,0]+cm[0,1]+cm[0,2]+cm[0,3])\n",
    "    print('Sensitivity class 0: ', sensitivity[0])\n",
    "    sensitivity[1] = cm[1,1]/(cm[1,0]+cm[1,1]+cm[1,2]+cm[1,3])\n",
    "    print('Sensitivity class 1: ', sensitivity[1])\n",
    "    sensitivity[2] = cm[2,2]/(cm[2,0]+cm[2,1]+cm[2,2]+cm[2,3])\n",
    "    print('Sensitivity class 2: ', sensitivity[2])\n",
    "    sensitivity[3] = cm[3,3]/(cm[3,0]+cm[3,1]+cm[3,2]+cm[3,3])\n",
    "    print('Sensitivity class 3: ', sensitivity[3])\n",
    "    print('Average sensitivity:',np.mean(sensitivity))\n",
    "    print()\n",
    "\n",
    "    specificity = [0,0,0,0]\n",
    "    specificity[0] = (cm[1,1]+cm[2,2]+cm[3,3])/((cm[1,1]+cm[2,2]+cm[3,3]) + (cm[1,0]+cm[2,0]+cm[3,0]))\n",
    "    print('Specificity class 0: ', specificity[0])\n",
    "    specificity[1] = (cm[0,0]+cm[2,2]+cm[3,3])/((cm[0,0]+cm[2,2]+cm[3,3]) + (cm[0,1]+cm[2,1]+cm[3,1]))\n",
    "    print('Specificity class 1: ', specificity[1])\n",
    "    specificity[2] = (cm[0,0]+cm[1,1]+cm[3,3])/((cm[0,0]+cm[1,1]+cm[3,3]) + (cm[0,2]+cm[1,2]+cm[3,2]))\n",
    "    print('Specificity class 2: ', specificity[2])\n",
    "    specificity[3] = (cm[0,0]+cm[1,1]+cm[2,2])/((cm[0,0]+cm[1,1]+cm[2,2]) + (cm[0,3]+cm[1,3]+cm[2,3]))\n",
    "    print('Specificity class 3: ', specificity[3])\n",
    "    print('Average specificity:',np.mean(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
